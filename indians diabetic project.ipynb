{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indians Diabetic Prediction (To predict diabetes using PIMA Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library , Load data and View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/neethu/Downloads/indiansdiabetic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>1.1426</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>1.8912</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0638</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>1.2214</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  \\\n",
       "0           6           148            72         35        0  33.6   \n",
       "1           1            85            66         29        0  26.6   \n",
       "2           8           183            64          0        0  23.3   \n",
       "3           1            89            66         23       94  28.1   \n",
       "4           0           137            40         35      168  43.1   \n",
       "..        ...           ...           ...        ...      ...   ...   \n",
       "763        10           101            76         48      180  32.9   \n",
       "764         2           122            70         27        0  36.8   \n",
       "765         5           121            72         23      112  26.2   \n",
       "766         1           126            60          0        0  30.1   \n",
       "767         1            93            70         31        0  30.4   \n",
       "\n",
       "     diab_pred  age    skin  diabetes  \n",
       "0        0.627   50  1.3790      True  \n",
       "1        0.351   31  1.1426     False  \n",
       "2        0.672   32  0.0000      True  \n",
       "3        0.167   21  0.9062     False  \n",
       "4        2.288   33  1.3790      True  \n",
       "..         ...  ...     ...       ...  \n",
       "763      0.171   63  1.8912     False  \n",
       "764      0.340   27  1.0638     False  \n",
       "765      0.245   30  0.9062     False  \n",
       "766      0.349   47  0.0000      True  \n",
       "767      0.315   23  1.2214     False  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>1.1426</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
       "0         6           148            72         35        0  33.6      0.627   \n",
       "1         1            85            66         29        0  26.6      0.351   \n",
       "2         8           183            64          0        0  23.3      0.672   \n",
       "3         1            89            66         23       94  28.1      0.167   \n",
       "4         0           137            40         35      168  43.1      2.288   \n",
       "\n",
       "   age    skin  diabetes  \n",
       "0   50  1.3790      True  \n",
       "1   31  1.1426     False  \n",
       "2   32  0.0000      True  \n",
       "3   21  0.9062     False  \n",
       "4   33  1.3790      True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>1.8912</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0638</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>1.2214</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  \\\n",
       "763        10           101            76         48      180  32.9   \n",
       "764         2           122            70         27        0  36.8   \n",
       "765         5           121            72         23      112  26.2   \n",
       "766         1           126            60          0        0  30.1   \n",
       "767         1            93            70         31        0  30.4   \n",
       "\n",
       "     diab_pred  age    skin  diabetes  \n",
       "763      0.171   63  1.8912     False  \n",
       "764      0.340   27  1.0638     False  \n",
       "765      0.245   30  0.9062     False  \n",
       "766      0.349   47  0.0000      True  \n",
       "767      0.315   23  1.2214     False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 10)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_preg        0\n",
       "glucose_conc    0\n",
       "diastolic_bp    0\n",
       "thickness       0\n",
       "insulin         0\n",
       "bmi             0\n",
       "diab_pred       0\n",
       "age             0\n",
       "skin            0\n",
       "diabetes        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    500\n",
       "True     268\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_preg', 'glucose_conc', 'diastolic_bp', 'thickness', 'insulin',\n",
       "       'bmi', 'diab_pred', 'age', 'skin', 'diabetes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_preg          int64\n",
       "glucose_conc      int64\n",
       "diastolic_bp      int64\n",
       "thickness         int64\n",
       "insulin           int64\n",
       "bmi             float64\n",
       "diab_pred       float64\n",
       "age               int64\n",
       "skin            float64\n",
       "diabetes           bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check For Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_preg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose_conc</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diastolic_bp</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diab_pred</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              num_preg  glucose_conc  diastolic_bp  thickness   insulin  \\\n",
       "num_preg      1.000000      0.129459      0.141282  -0.081672 -0.073535   \n",
       "glucose_conc  0.129459      1.000000      0.152590   0.057328  0.331357   \n",
       "diastolic_bp  0.141282      0.152590      1.000000   0.207371  0.088933   \n",
       "thickness    -0.081672      0.057328      0.207371   1.000000  0.436783   \n",
       "insulin      -0.073535      0.331357      0.088933   0.436783  1.000000   \n",
       "bmi           0.017683      0.221071      0.281805   0.392573  0.197859   \n",
       "diab_pred    -0.033523      0.137337      0.041265   0.183928  0.185071   \n",
       "age           0.544341      0.263514      0.239528  -0.113970 -0.042163   \n",
       "skin         -0.081672      0.057328      0.207371   1.000000  0.436783   \n",
       "diabetes      0.221898      0.466581      0.065068   0.074752  0.130548   \n",
       "\n",
       "                   bmi  diab_pred       age      skin  diabetes  \n",
       "num_preg      0.017683  -0.033523  0.544341 -0.081672  0.221898  \n",
       "glucose_conc  0.221071   0.137337  0.263514  0.057328  0.466581  \n",
       "diastolic_bp  0.281805   0.041265  0.239528  0.207371  0.065068  \n",
       "thickness     0.392573   0.183928 -0.113970  1.000000  0.074752  \n",
       "insulin       0.197859   0.185071 -0.042163  0.436783  0.130548  \n",
       "bmi           1.000000   0.140647  0.036242  0.392573  0.292695  \n",
       "diab_pred     0.140647   1.000000  0.033561  0.183928  0.173844  \n",
       "age           0.036242   0.033561  1.000000 -0.113970  0.238356  \n",
       "skin          0.392573   0.183928 -0.113970  1.000000  0.074752  \n",
       "diabetes      0.292695   0.173844  0.238356  0.074752  1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    500\n",
       "True     268\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the diabetes column data from boolean to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_values = {True:1,False:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diabetes']=data['diabetes'].map(map_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_preg        0\n",
       "glucose_conc    0\n",
       "diastolic_bp    0\n",
       "thickness       0\n",
       "insulin         0\n",
       "bmi             0\n",
       "diab_pred       0\n",
       "age             0\n",
       "skin            0\n",
       "diabetes        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use heatmap to check Null values present or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "763    0\n",
       "764    0\n",
       "765    0\n",
       "766    1\n",
       "767    0\n",
       "Name: diabetes, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libary train_test_split for spliting train test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import SimpleImputer to fill zero values with mean of that column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "fillvalues = SimpleImputer(missing_values=0, strategy='mean', fill_value=None, verbose=0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fillvalues.fit_transform(X_train)\n",
    "X_test = fillvalues.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=10)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest_model = RandomForestClassifier(random_state=10)\n",
    "\n",
    "random_forest_model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,  16],\n",
       "       [ 41,  46]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train_data = random_forest_model.predict(X_test)\n",
    "#confusison matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,predict_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predict_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       144\n",
      "           1       0.74      0.53      0.62        87\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.75      0.71      0.72       231\n",
      "weighted avg       0.75      0.75      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predict_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization with XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter optimization using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:19] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7]},\n",
       "                   scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train,y_train.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.3, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.3, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:53] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.3, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  18]\n",
      " [ 38  49]]\n",
      "0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cn = confusion_matrix(y_test,y_pred)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "print(cn)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:05] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:05] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:05] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:05] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:05] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:06] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:06] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:06] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:06] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:06] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/neethu/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(classifier,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75925926, 0.81481481, 0.88888889, 0.77777778, 0.72222222,\n",
       "       0.7037037 , 0.87037037, 0.69811321, 0.71698113, 0.81132075])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776345213137666"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       144\n",
      "           1       0.73      0.56      0.64        87\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.75      0.72      0.73       231\n",
      "weighted avg       0.75      0.76      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
